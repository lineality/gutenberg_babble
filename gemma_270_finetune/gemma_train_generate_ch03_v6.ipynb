{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb9344eb-22a2-48d2-a72a-827bbc9b6a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook gemma_train_generate_ch03_v4.ipynb to script\n",
      "[NbConvertApp] Writing 60069 bytes to gemma_train_generate_ch03_v4.py\n"
     ]
    }
   ],
   "source": [
    "# turn this into a .py file\n",
    "!jupyter nbconvert --to script gemma_train_generate_ch03_v5.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f3865-6a3e-4367-9112-75d6ea7a3244",
   "metadata": {},
   "source": [
    "# Training Gemma\n",
    "\n",
    "### see: new .py file -> train_gemma.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b598a-465a-4c95-838f-233ca8b3d679",
   "metadata": {},
   "source": [
    "# TODO List\n",
    "\n",
    "### 1. \n",
    "- gutenberg txt fine tuning\n",
    "- epub-conversion fine-tuning\n",
    "- alpaca/instruct fine tuning\n",
    "- synthetic data fine tuning\n",
    "  1. \"Who's coming to the party\"\n",
    "- testing from-nothing training\n",
    "- base model trimming, pruning\n",
    "- classification head\n",
    "- embedding head\n",
    "- larger gemma-type models\n",
    "- CPU-only version\n",
    "- quantizing model after training\n",
    "- dynamic-embeddings\n",
    "- IoT Data\n",
    "- Biological Signals & Behavior\n",
    "  1. birdsong\n",
    "  2. ants\n",
    "  3. population stability\n",
    "\n",
    "### 2. \n",
    "- full model training vs. lora-layer addition\n",
    "- saving an reloading weights\n",
    "\n",
    "### 3. \n",
    "- using the gemma 270m archetecture (or slight modification)\n",
    "  1. adjust archetecture to compared across same synthetic data training\n",
    "- making a public or crowd-sourced open MIT/APACHE2 weight set.\n",
    "- STEM-Net Benchmarks: a range of synthetic training data types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4a437-fabf-404b-ad3b-6d0e206f28b2",
   "metadata": {},
   "source": [
    "# Based on rasbt, Sebastian Raschhka's (fabuloustastic) notebooks and book:\n",
    "\n",
    "\"\n",
    "Supplementary code for the Build a Large Language Model From Scratch book by Sebastian Raschka\n",
    "\n",
    "Code repository: https://github.com/rasbt/LLMs-from-scratch\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde77f2-6af3-4781-8597-89ecd3f41a52",
   "metadata": {
    "id": "efde77f2-6af3-4781-8597-89ecd3f41a52"
   },
   "source": [
    "# Gemma 3 270M From Scratch (A Standalone Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d",
   "metadata": {
    "id": "55cdef4d-de59-4a65-89f9-fa2a8ef3471d"
   },
   "source": [
    "- This notebook is purposefully minimal and focuses on the code to re-implement Gemma 3 270M in pure PyTorch without relying on other external LLM libraries\n",
    "- For more information, see the official [Gemma 3 270M model card](https://huggingface.co/google/gemma-3-270m)\n",
    "\n",
    "- Below is a side-by-side comparison with Qwen3 0.6B as a reference model; if you are interested in the Qwen3 0.6B standalone notebook, you can find it [here](../11_qwen3)\n",
    "<br>\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/gemma3/gemma3-vs-qwen3.webp?1\">\n",
    "  \n",
    "  \n",
    "- About the code:\n",
    "  - all code is my own code, mapping the Gemma 3 architecture onto the model code implemented in my [Build A Large Language Model (From Scratch)](http://mng.bz/orYv) book; the code is released under a permissive open-source Apache 2.0 license (see [LICENSE.txt](https://github.com/rasbt/LLMs-from-scratch/blob/main/LICENSE.txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c201adb-747e-437b-9a62-442802941e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -r https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/refs/heads/main/ch05/07_gpt_to_llama/requirements-extra.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd1b65a8-4301-444a-bd7c-a6f2bd1df9df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dd1b65a8-4301-444a-bd7c-a6f2bd1df9df",
    "outputId": "4f762354-e0a3-4cc2-e5d4-e61a227a202c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.8.0\n",
      "numpy version: 2.3.2\n",
      "jupyter version: 1.1.1\n",
      "huggingface-hub version: 0.34.4\n",
      "tokenizers version: 0.22.0\n",
      "safetensors version: 0.6.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "# modified\n",
    "pkgs = [\n",
    "\"torch\",  # to implement the model\n",
    "\"numpy\",\n",
    "\"jupyter\",  # to run this notebook\n",
    "\"huggingface-hub\",  # to download pretrained weights\n",
    "\"tokenizers\",  # to implement the tokenizer\n",
    "\"safetensors\",\n",
    "]\n",
    "\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e96fbb-8e16-4f6d-835f-c6159321280b",
   "metadata": {},
   "source": [
    "- This notebook supports both the base model and the instructmodel; which model to use can be controlled via the following flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "70a90338-624a-4706-aa55-6b4358070194",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_INSTRUCT_MODEL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653410a6-dd2b-4eb2-a722-23d9782e726d",
   "metadata": {
    "id": "653410a6-dd2b-4eb2-a722-23d9782e726d"
   },
   "source": [
    "&nbsp;\n",
    "# 1. Architecture code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82076c21-9331-4dcd-b017-42b046cf1a60",
   "metadata": {
    "id": "82076c21-9331-4dcd-b017-42b046cf1a60"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "        self.fc2 = nn.Linear(cfg[\"emb_dim\"], cfg[\"hidden_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "        self.fc3 = nn.Linear(cfg[\"hidden_dim\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"], bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x)\n",
    "        x = nn.functional.gelu(x_fc1, approximate=\"tanh\") * x_fc2\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56715760-37e1-433e-89da-04864c139a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self, emb_dim, eps=1e-6, bias=False):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        # Gemma3 stores zero-centered weights and uses (1 + weight) during forward\n",
    "        self.scale = nn.Parameter(torch.zeros(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Match HF Gemma3: compute norm in float32, then scale by (1 + w)\n",
    "        input_dtype = x.dtype\n",
    "        x_f = x.float()\n",
    "        var = x_f.pow(2).mean(dim=-1, keepdim=True)\n",
    "        x_norm = x_f * torch.rsqrt(var + self.eps)\n",
    "        out = x_norm * (1.0 + self.scale.float())\n",
    "         \n",
    "        if self.shift is not None:\n",
    "            out = out + self.shift.float()\n",
    "         \n",
    "        return out.to(input_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b9a346f-5826-4083-9162-abd56afc03f0",
   "metadata": {
    "id": "4b9a346f-5826-4083-9162-abd56afc03f0"
   },
   "outputs": [],
   "source": [
    "def compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n",
    "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
    "\n",
    "    # Compute the inverse frequencies\n",
    "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
    "\n",
    "    # Generate position indices\n",
    "    positions = torch.arange(context_length, dtype=dtype)\n",
    "\n",
    "    # Compute the angles\n",
    "    angles = positions[:, None] * inv_freq[None, :]  # Shape: (context_length, head_dim // 2)\n",
    "\n",
    "    # Expand angles to match the head_dim\n",
    "    angles = torch.cat([angles, angles], dim=1)  # Shape: (context_length, head_dim)\n",
    "\n",
    "    # Precompute sine and cosine\n",
    "    cos = torch.cos(angles)\n",
    "    sin = torch.sin(angles)\n",
    "\n",
    "    return cos, sin\n",
    "\n",
    "\n",
    "def apply_rope(x, cos, sin):\n",
    "    # x: (batch_size, num_heads, seq_len, head_dim)\n",
    "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
    "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
    "\n",
    "    # Split x into first half and second half\n",
    "    x1 = x[..., : head_dim // 2]  # First half\n",
    "    x2 = x[..., head_dim // 2 :]  # Second half\n",
    "\n",
    "    # Adjust sin and cos shapes\n",
    "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n",
    "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Apply the rotary transformation\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    x_rotated = (x * cos) + (rotated * sin)\n",
    "\n",
    "    # It's ok to use lower-precision after applying cos and sin rotation\n",
    "    return x_rotated.to(dtype=x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8169ab5-f976-4222-a2e1-eb1cabf267cb",
   "metadata": {
    "id": "e8169ab5-f976-4222-a2e1-eb1cabf267cb"
   },
   "outputs": [],
   "source": [
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self, d_in, num_heads, num_kv_groups, head_dim=None, qk_norm=False,\n",
    "        query_pre_attn_scalar=None, dtype=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert num_heads % num_kv_groups == 0, \"num_heads must be divisible by num_kv_groups\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_groups = num_kv_groups\n",
    "        self.group_size = num_heads // num_kv_groups\n",
    "\n",
    "        if head_dim is None:\n",
    "            assert d_in % num_heads == 0, \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n",
    "            head_dim = d_in // num_heads\n",
    "\n",
    "        self.head_dim = head_dim\n",
    "        self.d_out = num_heads * head_dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, self.d_out, bias=False, dtype=dtype)\n",
    "        self.W_key = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
    "        self.W_value = nn.Linear(d_in, num_kv_groups * head_dim, bias=False, dtype=dtype)\n",
    "\n",
    "        self.out_proj = nn.Linear(self.d_out, d_in, bias=False, dtype=dtype)\n",
    "\n",
    "        if qk_norm:\n",
    "            self.q_norm = RMSNorm(head_dim, eps=1e-6)\n",
    "            self.k_norm = RMSNorm(head_dim, eps=1e-6)\n",
    "        else:\n",
    "            self.q_norm = self.k_norm = None\n",
    "\n",
    "        if query_pre_attn_scalar is not None:\n",
    "            self.scaling = (query_pre_attn_scalar) ** -0.5\n",
    "        else:\n",
    "            self.scaling = (head_dim) ** -0.5\n",
    "\n",
    "\n",
    "    def forward(self, x, mask, cos, sin):\n",
    "        b, num_tokens, _ = x.shape\n",
    "\n",
    "        # Apply projections\n",
    "        queries = self.W_query(x)  # (b, num_tokens, num_heads * head_dim)\n",
    "        keys = self.W_key(x)       # (b, num_tokens, num_kv_groups * head_dim)\n",
    "        values = self.W_value(x)   # (b, num_tokens, num_kv_groups * head_dim)\n",
    "\n",
    "        # Reshape\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        keys = keys.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
    "        values = values.view(b, num_tokens, self.num_kv_groups, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Optional normalization\n",
    "        if self.q_norm:\n",
    "            queries = self.q_norm(queries)\n",
    "        if self.k_norm:\n",
    "            keys = self.k_norm(keys)\n",
    "\n",
    "        # Apply RoPE\n",
    "        queries = apply_rope(queries, cos, sin)\n",
    "        keys = apply_rope(keys, cos, sin)\n",
    "\n",
    "        # Expand K and V to match number of heads\n",
    "        keys = keys.repeat_interleave(self.group_size, dim=1)\n",
    "        values = values.repeat_interleave(self.group_size, dim=1)\n",
    "\n",
    "        # Scale queries\n",
    "        queries = queries * self.scaling\n",
    "\n",
    "        # Attention\n",
    "        attn_scores = queries @ keys.transpose(2, 3)\n",
    "        attn_scores = attn_scores.masked_fill(mask, -torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "\n",
    "        context = (attn_weights @ values).transpose(1, 2).reshape(b, num_tokens, self.d_out)\n",
    "        return self.out_proj(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "457cb2f8-50c1-4045-8a74-f181bfb5fea9",
   "metadata": {
    "id": "457cb2f8-50c1-4045-8a74-f181bfb5fea9"
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg, attn_type):\n",
    "        super().__init__()\n",
    "        self.attn_type = attn_type \n",
    "\n",
    "        self.att = GroupedQueryAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            num_kv_groups=cfg[\"n_kv_groups\"],\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            qk_norm=cfg[\"qk_norm\"],\n",
    "            query_pre_attn_scalar=cfg[\"query_pre_attn_scalar\"],\n",
    "            dtype=cfg[\"dtype\"],\n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.input_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.post_attention_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.pre_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.post_feedforward_layernorm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        mask_global,\n",
    "        mask_local,\n",
    "        cos_global,\n",
    "        sin_global,\n",
    "        cos_local,\n",
    "        sin_local,\n",
    "    ):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.input_layernorm(x)\n",
    "\n",
    "        if self.attn_type == \"sliding_attention\":\n",
    "            attn_mask = mask_local\n",
    "            cos = cos_local\n",
    "            sin = sin_local\n",
    "        else:\n",
    "            attn_mask = mask_global\n",
    "            cos = cos_global\n",
    "            sin = sin_global\n",
    "        \n",
    "        x_attn = self.att(x, attn_mask, cos, sin)\n",
    "        x_attn = self.post_attention_layernorm(x_attn)\n",
    "        x = shortcut + x_attn\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x_ffn = self.pre_feedforward_layernorm(x)\n",
    "        x_ffn = self.ff(x_ffn)\n",
    "        x_ffn = self.post_feedforward_layernorm(x_ffn)\n",
    "        x = shortcut + x_ffn\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e88de3e3-9f07-42cc-816b-28dbd46e96c4",
   "metadata": {
    "id": "e88de3e3-9f07-42cc-816b-28dbd46e96c4"
   },
   "outputs": [],
   "source": [
    "class Gemma3Model(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        assert cfg[\"layer_types\"] is not None and len(cfg[\"layer_types\"]) == cfg[\"n_layers\"]\n",
    "        \n",
    "        # Main model parameters\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"], dtype=cfg[\"dtype\"])\n",
    "\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(cfg, attn_type)for attn_type in cfg[\"layer_types\"]\n",
    "        ])\n",
    "\n",
    "        self.final_norm = RMSNorm(cfg[\"emb_dim\"], eps=1e-6)\n",
    "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False, dtype=cfg[\"dtype\"])\n",
    "        self.cfg = cfg\n",
    "\n",
    "        # Reusable utilities    \n",
    "        cos_local, sin_local = compute_rope_params(\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            theta_base=cfg[\"rope_local_base\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        cos_global, sin_global = compute_rope_params(\n",
    "            head_dim=cfg[\"head_dim\"],\n",
    "            theta_base=cfg[\"rope_base\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.register_buffer(\"cos_local\", cos_local, persistent=False)\n",
    "        self.register_buffer(\"sin_local\", sin_local, persistent=False)\n",
    "        self.register_buffer(\"cos_global\", cos_global, persistent=False)\n",
    "        self.register_buffer(\"sin_global\", sin_global, persistent=False)\n",
    "    \n",
    "    def _create_masks(self, seq_len, device):\n",
    "        ones = torch.ones((seq_len, seq_len), dtype=torch.bool, device=device)\n",
    "    \n",
    "        # mask_global (future is masked: j > i)\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        #  i\n",
    "        #     0:  0 1 1 1 1 1 1 1\n",
    "        #     1:  0 0 1 1 1 1 1 1\n",
    "        #     2:  0 0 0 1 1 1 1 1\n",
    "        #     3:  0 0 0 0 1 1 1 1\n",
    "        #     4:  0 0 0 0 0 1 1 1\n",
    "        #     5:  0 0 0 0 0 0 1 1\n",
    "        #     6:  0 0 0 0 0 0 0 1\n",
    "        #     7:  0 0 0 0 0 0 0 0\n",
    "        mask_global = torch.triu(ones, diagonal=1)\n",
    "    \n",
    "        # far_past (too far back is masked: i - j >= sliding_window)\n",
    "        # where sliding_window = 4\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        #  i\n",
    "        #     0:  0 0 0 0 0 0 0 0\n",
    "        #     1:  0 0 0 0 0 0 0 0\n",
    "        #     2:  0 0 0 0 0 0 0 0\n",
    "        #     3:  0 0 0 0 0 0 0 0\n",
    "        #     4:  1 0 0 0 0 0 0 0\n",
    "        #     5:  1 1 0 0 0 0 0 0\n",
    "        #     6:  1 1 1 0 0 0 0 0\n",
    "        #     7:  1 1 1 1 0 0 0 0\n",
    "        far_past = torch.triu(ones, diagonal=self.cfg[\"sliding_window\"]).T\n",
    "    \n",
    "        # Local (sliding_window) = future OR far-past\n",
    "        # mask_local\n",
    "        #     j:  0 1 2 3 4 5 6 7\n",
    "        # i\n",
    "        # 0:      0 1 1 1 1 1 1 1\n",
    "        # 1:      0 0 1 1 1 1 1 1\n",
    "        # 2:      0 0 0 1 1 1 1 1\n",
    "        # 3:      0 0 0 0 1 1 1 1\n",
    "        # 4:      1 0 0 0 0 1 1 1\n",
    "        # 5:      1 1 0 0 0 0 1 1\n",
    "        # 6:      1 1 1 0 0 0 0 1\n",
    "        # 7:      1 1 1 1 0 0 0 0\n",
    "        mask_local = mask_global | far_past\n",
    "        return mask_global, mask_local\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        # Forward pass\n",
    "        b, seq_len = input_ids.shape\n",
    "        x = self.tok_emb(input_ids) * (self.cfg[\"emb_dim\"] ** 0.5)\n",
    "        mask_global, mask_local = self._create_masks(seq_len, x.device)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            x = block(\n",
    "                x,\n",
    "                mask_global=mask_global,\n",
    "                mask_local=mask_local,\n",
    "                cos_global=self.cos_global,\n",
    "                sin_global=self.sin_global,\n",
    "                cos_local=self.cos_local,\n",
    "                sin_local=self.sin_local,\n",
    "            )\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x.to(self.cfg[\"dtype\"]))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2d201f-74ad-4d63-ab9c-601b00674a48",
   "metadata": {
    "id": "be2d201f-74ad-4d63-ab9c-601b00674a48"
   },
   "source": [
    "&nbsp;\n",
    "# 2. Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caa142fa-b375-4e78-b392-2072ced666f3",
   "metadata": {
    "id": "caa142fa-b375-4e78-b392-2072ced666f3"
   },
   "outputs": [],
   "source": [
    "GEMMA3_CONFIG_270M = {\n",
    "    \"vocab_size\": 262_144,\n",
    "    \"context_length\": 32_768,\n",
    "    \"emb_dim\": 640,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 18,\n",
    "    \"hidden_dim\": 2048,\n",
    "    \"head_dim\": 256,\n",
    "    \"qk_norm\": True,\n",
    "    \"n_kv_groups\": 1,\n",
    "    \"rope_local_base\": 10_000.0,\n",
    "    \"rope_base\": 1_000_000.0,\n",
    "    \"sliding_window\": 512,\n",
    "      \"layer_types\": [\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"sliding_attention\",\n",
    "        \"full_attention\"\n",
    "    ],\n",
    "    \"dtype\": torch.bfloat16,\n",
    "    \"query_pre_attn_scalar\": 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "156253fe-aacd-4da2-8f13-705f05c4b11e",
   "metadata": {
    "id": "156253fe-aacd-4da2-8f13-705f05c4b11e"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "model = Gemma3Model(GEMMA3_CONFIG_270M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaf86265-4e9d-4024-9ed0-99076944e304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gemma3Model(\n",
       "  (tok_emb): Embedding(262144, 640)\n",
       "  (blocks): ModuleList(\n",
       "    (0-17): 18 x TransformerBlock(\n",
       "      (att): GroupedQueryAttention(\n",
       "        (W_query): Linear(in_features=640, out_features=1024, bias=False)\n",
       "        (W_key): Linear(in_features=640, out_features=256, bias=False)\n",
       "        (W_value): Linear(in_features=640, out_features=256, bias=False)\n",
       "        (out_proj): Linear(in_features=1024, out_features=640, bias=False)\n",
       "        (q_norm): RMSNorm()\n",
       "        (k_norm): RMSNorm()\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (fc1): Linear(in_features=640, out_features=2048, bias=False)\n",
       "        (fc2): Linear(in_features=640, out_features=2048, bias=False)\n",
       "        (fc3): Linear(in_features=2048, out_features=640, bias=False)\n",
       "      )\n",
       "      (input_layernorm): RMSNorm()\n",
       "      (post_attention_layernorm): RMSNorm()\n",
       "      (pre_feedforward_layernorm): RMSNorm()\n",
       "      (post_feedforward_layernorm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (final_norm): RMSNorm()\n",
       "  (out_head): Linear(in_features=640, out_features=262144, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aca91d-4bee-45ce-993a-4ec5393abe2b",
   "metadata": {},
   "source": [
    "- A quick check that the forward pass works before continuing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adf0a6b7-b688-42c9-966e-c223d34db99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7539,  0.1060,  0.4805,  ...,  0.9375,  0.4043, -0.2383],\n",
       "         [-0.3418, -0.0576,  0.8984,  ..., -0.2432,  0.4629,  0.8242],\n",
       "         [-0.2695, -0.3281,  0.4102,  ...,  0.8750, -0.9727,  0.9844]]],\n",
       "       dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([1, 2, 3]).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "364e76ca-52f8-4fa5-af37-c4069f9694bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "364e76ca-52f8-4fa5-af37-c4069f9694bc",
    "outputId": "00d7e983-262e-4c65-f322-f4d999311988"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 435,870,336\n",
      "\n",
      "Total number of unique parameters: 268,098,176\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")\n",
    "\n",
    "# Account for weight tying\n",
    "total_params_normalized = total_params - model.tok_emb.weight.numel()\n",
    "print(f\"\\nTotal number of unique parameters: {total_params_normalized:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd5efb03-5a07-46e8-8607-93ed47549d2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd5efb03-5a07-46e8-8607-93ed47549d2b",
    "outputId": "65c1a95e-b502-4150-9e2e-da619d9053d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 (PyTorch default): 3.37 GB\n",
      "bfloat16: 1.69 GB\n"
     ]
    }
   ],
   "source": [
    "def model_memory_size(model, input_dtype=torch.float32):\n",
    "    total_params = 0\n",
    "    total_grads = 0\n",
    "    for param in model.parameters():\n",
    "        # Calculate total number of elements per parameter\n",
    "        param_size = param.numel()\n",
    "        total_params += param_size\n",
    "        # Check if gradients are stored for this parameter\n",
    "        if param.requires_grad:\n",
    "            total_grads += param_size\n",
    "\n",
    "    # Calculate buffer size (non-parameters that require memory)\n",
    "    total_buffers = sum(buf.numel() for buf in model.buffers())\n",
    "\n",
    "    # Size in bytes = (Number of elements) * (Size of each element in bytes)\n",
    "    # We assume parameters and gradients are stored in the same type as input dtype\n",
    "    element_size = torch.tensor(0, dtype=input_dtype).element_size()\n",
    "    total_memory_bytes = (total_params + total_grads + total_buffers) * element_size\n",
    "\n",
    "    # Convert bytes to gigabytes\n",
    "    total_memory_gb = total_memory_bytes / (1024**3)\n",
    "\n",
    "    return total_memory_gb\n",
    "\n",
    "print(f\"float32 (PyTorch default): {model_memory_size(model, input_dtype=torch.float32):.2f} GB\")\n",
    "print(f\"bfloat16: {model_memory_size(model, input_dtype=torch.bfloat16):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "31f12baf-f79b-499f-85c0-51328a6a20f5",
   "metadata": {
    "id": "31f12baf-f79b-499f-85c0-51328a6a20f5"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172f89f-d301-439f-b809-46169e5f5945",
   "metadata": {
    "id": "c172f89f-d301-439f-b809-46169e5f5945"
   },
   "source": [
    "&nbsp;\n",
    "# 4. Load pretrained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75166128-5899-4995-9b88-9672e135650e",
   "metadata": {
    "id": "75166128-5899-4995-9b88-9672e135650e"
   },
   "outputs": [],
   "source": [
    "def load_weights_into_gemma(model, param_config, params):\n",
    "\n",
    "    def assign(left, right, tensor_name=\"unknown\"):\n",
    "        if left.shape != right.shape:\n",
    "            raise ValueError(\n",
    "                f\"Shape mismatch in tensor '{tensor_name}'. Left: {left.shape}, Right: {right.shape}\"\n",
    "            )\n",
    "        return torch.nn.Parameter(right.clone().detach() if isinstance(right, torch.Tensor) else torch.tensor(right))\n",
    "\n",
    "    # Embedding weights\n",
    "    if \"model.embed_tokens.weight\" in params:\n",
    "        model.tok_emb.weight = assign(\n",
    "            model.tok_emb.weight,\n",
    "            params[\"model.embed_tokens.weight\"],\n",
    "            \"model.embed_tokens.weight\",\n",
    "        )\n",
    "\n",
    "    # Iterate over transformer layers\n",
    "    for l in range(param_config[\"n_layers\"]):\n",
    "        block = model.blocks[l]\n",
    "        att = block.att\n",
    "        # Attention projections\n",
    "        att.W_query.weight = assign(\n",
    "            att.W_query.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.q_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.q_proj.weight\",\n",
    "        )\n",
    "        att.W_key.weight = assign(\n",
    "            att.W_key.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.k_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.k_proj.weight\",\n",
    "        )\n",
    "        att.W_value.weight = assign(\n",
    "            att.W_value.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.v_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.v_proj.weight\",\n",
    "        )\n",
    "        att.out_proj.weight = assign(\n",
    "            att.out_proj.weight,\n",
    "            params[f\"model.layers.{l}.self_attn.o_proj.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.o_proj.weight\",\n",
    "        )\n",
    "        # QK normalization weights\n",
    "        att.q_norm.scale = assign(\n",
    "            att.q_norm.scale,\n",
    "            params[f\"model.layers.{l}.self_attn.q_norm.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.q_norm.weight\",\n",
    "        )\n",
    "        att.k_norm.scale = assign(\n",
    "            att.k_norm.scale,\n",
    "            params[f\"model.layers.{l}.self_attn.k_norm.weight\"],\n",
    "            f\"model.layers.{l}.self_attn.k_norm.weight\",\n",
    "        )\n",
    "        # Feed forward weights\n",
    "        block.ff.fc1.weight = assign(\n",
    "            block.ff.fc1.weight,\n",
    "            params[f\"model.layers.{l}.mlp.gate_proj.weight\"],\n",
    "            f\"model.layers.{l}.mlp.gate_proj.weight\",\n",
    "        )\n",
    "        block.ff.fc2.weight = assign(\n",
    "            block.ff.fc2.weight,\n",
    "            params[f\"model.layers.{l}.mlp.up_proj.weight\"],\n",
    "            f\"model.layers.{l}.mlp.up_proj.weight\",\n",
    "        )\n",
    "        block.ff.fc3.weight = assign(\n",
    "            block.ff.fc3.weight,\n",
    "            params[f\"model.layers.{l}.mlp.down_proj.weight\"],\n",
    "            f\"model.layers.{l}.mlp.down_proj.weight\",\n",
    "        )\n",
    "        # LayerNorm weights\n",
    "        block.input_layernorm.scale = assign(\n",
    "            block.input_layernorm.scale,\n",
    "            params[f\"model.layers.{l}.input_layernorm.weight\"],\n",
    "            f\"model.layers.{l}.input_layernorm.weight\",\n",
    "        )\n",
    "        block.post_attention_layernorm.scale = assign(\n",
    "            block.post_attention_layernorm.scale,\n",
    "            params[f\"model.layers.{l}.post_attention_layernorm.weight\"],\n",
    "            f\"model.layers.{l}.post_attention_layernorm.weight\",\n",
    "        )\n",
    "        # Pre‑ and post‑feed forward norms\n",
    "        pre_key = f\"model.layers.{l}.pre_feedforward_layernorm.weight\"\n",
    "        post_key = f\"model.layers.{l}.post_feedforward_layernorm.weight\"\n",
    "        if pre_key in params:\n",
    "            block.pre_feedforward_layernorm.scale = assign(\n",
    "                block.pre_feedforward_layernorm.scale,\n",
    "                params[pre_key],\n",
    "                pre_key,\n",
    "            )\n",
    "        if post_key in params:\n",
    "            block.post_feedforward_layernorm.scale = assign(\n",
    "                block.post_feedforward_layernorm.scale,\n",
    "                params[post_key],\n",
    "                post_key,\n",
    "            )\n",
    "\n",
    "    # Final LayerNorm\n",
    "    if \"model.norm.weight\" in params:\n",
    "        model.final_norm.scale = assign(\n",
    "            model.final_norm.scale,\n",
    "            params[\"model.norm.weight\"],\n",
    "            \"model.norm.weight\",\n",
    "        )\n",
    "    # Output head\n",
    "    if \"lm_head.weight\" in params:\n",
    "        model.out_head.weight = assign(\n",
    "            model.out_head.weight,\n",
    "            params[\"lm_head.weight\"],\n",
    "            \"lm_head.weight\",\n",
    "        )\n",
    "    elif \"model.embed_tokens.weight\" in params:\n",
    "        # Weight tying: reuse the embedding weights\n",
    "        model.out_head.weight = assign(\n",
    "            model.out_head.weight,\n",
    "            params[\"model.embed_tokens.weight\"],\n",
    "            \"model.embed_tokens.weight\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430340f2-78b9-4983-b74e-8395bbd7e574",
   "metadata": {},
   "source": [
    "- Please note that Google requires that you accept the Gemma 3 licensing terms before you can download the files; to do this, you have to create a Hugging Face Hub account and visit the [google/gemma-3-270m](https://huggingface.co/google/gemma-3-270m) repository to accept the terms\n",
    "- Next, you will need to create an access token; to generate an access token with READ permissions, click on the profile picture in the upper right and click on \"Settings\"\n",
    "\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/gpt-to-llama/settings.webp?1\" width=\"300px\">\n",
    "\n",
    "- Then, create and copy the access token so you can copy & paste it into the next code cell\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/bonus/gpt-to-llama/access-token.webp?1\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cee5292-f756-41dd-9b8d-c9b5c25d23f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run the following code if you are executing the notebook for the first time\n",
    "\n",
    "#from huggingface_hub import login\n",
    "#login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "699cb1b8-a67d-49fb-80a6-0dad9d81f392",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "9881b6995c3f49dc89e6992fd9ab660b",
      "17a3174e65c54476b2e0d1faf8f011ca",
      "1bbf2e62c0754d1593beb4105a7f1ac1",
      "b82112e1dec645d98aa1c1ba64abcb61",
      "271e2bd6a35e4a8b92de8697f7c0be5f",
      "90a79523187446dfa692723b2e5833a7",
      "431ffb83b8c14bf182f0430e07ea6154",
      "a8f1b72a33dd4b548de23fbd95e0da18",
      "25cc36132d384189acfbecc59483134b",
      "bfd06423ad544218968648016e731a46",
      "d029630b63ff44cf807ade428d2eb421"
     ]
    },
    "id": "699cb1b8-a67d-49fb-80a6-0dad9d81f392",
    "outputId": "55b2f28c-142f-4698-9d23-d27456d3ed6d"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from safetensors.torch import load_file\n",
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "\n",
    "CHOOSE_MODEL = \"270m\"\n",
    "\n",
    "if USE_INSTRUCT_MODEL:\n",
    "    repo_id = f\"google/gemma-3-{CHOOSE_MODEL}-it\"\n",
    "else:\n",
    "    repo_id = f\"google/gemma-3-{CHOOSE_MODEL}\"\n",
    "\n",
    "\n",
    "local_dir = Path(repo_id).parts[-1]\n",
    "\n",
    "if CHOOSE_MODEL == \"270m\":\n",
    "    weights_file = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=\"model.safetensors\",\n",
    "        local_dir=local_dir,\n",
    "    )\n",
    "    weights_dict = load_file(weights_file)\n",
    "else:\n",
    "    repo_dir = snapshot_download(repo_id=repo_id, local_dir=local_dir)\n",
    "    index_path = os.path.join(repo_dir, \"model.safetensors.index.json\")\n",
    "    with open(index_path, \"r\") as f:\n",
    "        index = json.load(f)\n",
    "\n",
    "    weights_dict = {}\n",
    "    for filename in set(index[\"weight_map\"].values()):\n",
    "        shard_path = os.path.join(repo_dir, filename)\n",
    "        shard = load_file(shard_path)\n",
    "        weights_dict.update(shard)\n",
    "\n",
    "load_weights_into_gemma(model, GEMMA3_CONFIG_270M, weights_dict)\n",
    "model.to(device)\n",
    "del weights_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b345491-3510-4397-92d3-cd0a3fa3deee",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "# 4. Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b68ab489-48e5-471e-a814-56cda2d60f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "\n",
    "class GemmaTokenizer:\n",
    "    def __init__(self, tokenizer_file_path: str):\n",
    "        tok_file = Path(tokenizer_file_path)\n",
    "        self._tok = Tokenizer.from_file(str(tok_file))\n",
    "        # Attempt to identify EOS and padding tokens\n",
    "        eos_token = \"<end_of_turn>\"\n",
    "        self.pad_token_id = eos_token\n",
    "        self.eos_token_id = eos_token\n",
    "\n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        return self._tok.encode(text).ids\n",
    "\n",
    "    def decode(self, ids: list[int]) -> str:\n",
    "        return self._tok.decode(ids, skip_special_tokens=False)\n",
    "\n",
    "\n",
    "def apply_chat_template(user_text):\n",
    "    return f\"<start_of_turn>user\\n{user_text}<end_of_turn>\\n<start_of_turn>model\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b6df8bc-7308-468e-93ce-2d5529ea7866",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_file_path = os.path.join(local_dir, \"tokenizer.json\")\n",
    "if not os.path.exists(tokenizer_file_path):\n",
    "    try:\n",
    "        tokenizer_file_path = hf_hub_download(repo_id=repo_id, filename=\"tokenizer.json\", local_dir=local_dir)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: failed to download tokenizer.json: {e}\")\n",
    "        tokenizer_file_path = \"tokenizer.json\"\n",
    "\n",
    "tokenizer = GemmaTokenizer(tokenizer_file_path=tokenizer_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1946b534-e3af-431a-a222-391a60bfa892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<bos><start_of_turn>user\\nGive me a short introduction to large language models.<end_of_turn>\\n<start_of_turn>model\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Give me a short introduction to large language models.\"\n",
    "prompt = apply_chat_template(\"Give me a short introduction to large language models.\")\n",
    "\n",
    "\n",
    "input_token_ids = tokenizer.encode(prompt)\n",
    "text = tokenizer.decode(input_token_ids)\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d07df1-4401-4792-b549-7c4cc5632323",
   "metadata": {
    "id": "57d07df1-4401-4792-b549-7c4cc5632323"
   },
   "source": [
    "&nbsp;\n",
    "# 5. Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6250333-9cf0-4f36-8e28-76be2eac1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally use torch.compile for an extra speed-up\n",
    "# model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b8401c6-e244-4cb7-9849-2ba71ce758d5",
   "metadata": {
    "id": "7b8401c6-e244-4cb7-9849-2ba71ce758d5"
   },
   "outputs": [],
   "source": [
    "def generate_text_basic_stream(model, token_ids, max_new_tokens, eos_token_id=None):\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            out = model(token_ids)[:, -1]\n",
    "            next_token = torch.argmax(out, dim=-1, keepdim=True)\n",
    "\n",
    "            if (eos_token_id is not None\n",
    "                   and torch.all(next_token == eos_token_id)):\n",
    "               break\n",
    "\n",
    "            yield next_token\n",
    "            \n",
    "            token_ids = torch.cat([token_ids, next_token], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c7a04fa-6aac-416b-8f63-f1e19227633d",
   "metadata": {
    "id": "1c7a04fa-6aac-416b-8f63-f1e19227633d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Large language models (LLMs) are sophisticated artificial intelligence systems that can understand, generate, and manipulate human language. They are trained on massive amounts of text data to learn patterns and relationships within language, enabling them to perform a wide range of tasks, from writing articles and answering questions to translating languages and summarizing information.\n"
     ]
    }
   ],
   "source": [
    "input_token_ids_tensor = torch.tensor(input_token_ids, device=device).unsqueeze(0)\n",
    "\n",
    "\n",
    "for token in generate_text_basic_stream(\n",
    "    model=model,\n",
    "    token_ids=input_token_ids_tensor,\n",
    "    max_new_tokens=500,\n",
    "    eos_token_id=tokenizer.encode(\"<end_of_turn>\")[-1]\n",
    "):\n",
    "    token_id = token.squeeze(0).tolist()\n",
    "    print(\n",
    "        tokenizer.decode(token_id),\n",
    "        end=\"\",\n",
    "        flush=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549324d6-5c71-4147-ae21-2e67675faa3d",
   "metadata": {
    "id": "549324d6-5c71-4147-ae21-2e67675faa3d"
   },
   "source": [
    "&nbsp;\n",
    "# What's next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6edaaae-2de1-406c-8ffa-897cdfa3808c",
   "metadata": {
    "id": "e6edaaae-2de1-406c-8ffa-897cdfa3808c"
   },
   "source": [
    "- Check out the [README.md](./README.md), to use this model via the `llms_from_scratch` package\n",
    "- For those interested in a comprehensive guide on building a large language model from scratch and gaining a deeper understanding of its mechanics, you might like my [Build a Large Language Model (From Scratch)](http://mng.bz/orYv)\n",
    "\n",
    "<a href=\"http://mng.bz/orYv\"><img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/cover-small.webp\" width=\"100px\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9093f6-5d56-4a63-864d-1677b0534ec3",
   "metadata": {},
   "source": [
    "\"end of original code\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22a9a47-d6d2-4727-842a-adc29fcdb276",
   "metadata": {},
   "source": [
    "# Mod: Training Gemma\n",
    "\n",
    "Points to Emphasize:\n",
    "\n",
    "Architecture Differences:\n",
    "\n",
    "RoPE vs learned positional embeddings\n",
    "Sliding window attention\n",
    "RMSNorm vs LayerNorm\n",
    "Larger vocabulary impact\n",
    "\n",
    "\n",
    "Memory Management:\n",
    "\n",
    "Why we reduce context length\n",
    "Gradient accumulation explanation\n",
    "bfloat16 precision benefits\n",
    "\n",
    "\n",
    "Tokenization Differences:\n",
    "\n",
    "Larger vocabulary effects\n",
    "Different special tokens\n",
    "Chat template for instruct models\n",
    "\n",
    "\n",
    "Training Adaptations:\n",
    "\n",
    "No dropout in Gemma\n",
    "Different learning rate\n",
    "Gradient clipping importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00862c54-14e0-4eca-8872-76ba6e00a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c263768b-092e-4996-8198-4ae2524001ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d0f224-bad0-40c9-8d84-1d455fbb3c55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c087dbc-e132-45c4-a5dc-74aad4765aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Training Gemma 3 270M\n",
    "# \n",
    "# This section demonstrates how to train/fine-tune the Gemma 3 270M model using the training infrastructure\n",
    "# we've developed. We'll walk through data preparation, model initialization, and the training process.\n",
    "\n",
    "# ### Setup and Environment Check\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "from safetensors.torch import load_file\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tokenizers import Tokenizer\n",
    "import time\n",
    "import psutil\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d2510fc-9394-4487-aeac-3cb612651984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA RTX 3500 Ada Generation Laptop GPU\n",
      "Total memory: 12282.0 MB\n",
      "Free memory: 11992.0 MB\n",
      "Used memory: 12.0 MB\n",
      "\n",
      "PyTorch allocated: 0.00 GB\n",
      "PyTorch reserved: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Check GPU availability and memory\n",
    "def check_gpu_memory():\n",
    "    if torch.cuda.is_available():\n",
    "        gpu = GPUtil.getGPUs()[0]\n",
    "        print(f\"GPU: {gpu.name}\")\n",
    "        print(f\"Total memory: {gpu.memoryTotal:.1f} MB\")\n",
    "        print(f\"Free memory: {gpu.memoryFree:.1f} MB\")\n",
    "        print(f\"Used memory: {gpu.memoryUsed:.1f} MB\")\n",
    "        \n",
    "        # PyTorch's view\n",
    "        device_id = torch.cuda.current_device()\n",
    "        allocated = torch.cuda.memory_allocated(device_id) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(device_id) / 1024**3\n",
    "        print(f\"\\nPyTorch allocated: {allocated:.2f} GB\")\n",
    "        print(f\"PyTorch reserved: {reserved:.2f} GB\")\n",
    "    else:\n",
    "        print(\"No GPU available. Training will be slow on CPU.\")\n",
    "        print(f\"CPU cores: {psutil.cpu_count()}\")\n",
    "        print(f\"RAM: {psutil.virtual_memory().total / 1024**3:.1f} GB\")\n",
    "\n",
    "check_gpu_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8945a77-62cf-48b2-97f6-81182790dd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()  # Clear any cached memory\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "print(f\"\\nUsing device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d96d19a-5b9a-49de-8cf4-ad4e3d2ff1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Downloading alice.txt...\n",
      "Total characters loaded: 144,604\n",
      "First 200 characters:\n",
      "\n",
      "[Illustration]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Alice’s Adventures in Wonderland\n",
      "\n",
      "by Lewis Carroll\n",
      "\n",
      "THE MILLENNIUM FULCRUM EDITION 3.0\n",
      "\n",
      "Contents\n",
      "\n",
      " CHAPTER I.     Down the Rabbit-Hole\n",
      " CHAPTER II.    The Pool of Tears\n",
      " CHAPTER II\n",
      "\n",
      "Last 200 characters:\n",
      "m of Wonderland of long ago: and how she\n",
      "would feel with all their simple sorrows, and find a pleasure in all\n",
      "their simple joys, remembering her own child-life, and the happy summer\n",
      "days.\n",
      "\n",
      "THE END\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We'll use Project Gutenberg texts for training. This provides more data than \"The Verdict\" \n",
    "# used in the GPT-2 example, which is necessary for the larger vocabulary of Gemma.\n",
    "\n",
    "# Download multiple Gutenberg texts for more training data\n",
    "def download_gutenberg_texts():\n",
    "    \"\"\"Download a collection of public domain texts for training\"\"\"\n",
    "    \n",
    "    texts = {\n",
    "        # \"shakespeare.txt\": \"https://www.gutenberg.org/files/100/100-0.txt\",  # Complete Shakespeare\n",
    "        \"alice.txt\": \"https://www.gutenberg.org/files/11/11-0.txt\",  # Alice in Wonderland\n",
    "        # \"pride_prejudice.txt\": \"https://www.gutenberg.org/files/1342/1342-0.txt\",  # Pride and Prejudice\n",
    "        # \"frankenstein.txt\": \"https://www.gutenberg.org/files/84/84-0.txt\",  # Frankenstein\n",
    "    }\n",
    "    \n",
    "    combined_text = \"\"\n",
    "    \n",
    "    for filename, url in texts.items():\n",
    "        file_path = f\"data/{filename}\"\n",
    "        os.makedirs(\"data\", exist_ok=True)\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            with urllib.request.urlopen(url) as response:\n",
    "                text_data = response.read().decode('utf-8')\n",
    "            with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(text_data)\n",
    "        else:\n",
    "            print(f\"Loading existing {filename}...\")\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                text_data = file.read()\n",
    "        \n",
    "        # Clean and combine texts\n",
    "        # Remove Gutenberg headers/footers if present\n",
    "        start_marker = \"*** START OF\"\n",
    "        end_marker = \"*** END OF\"\n",
    "        \n",
    "        start_idx = text_data.find(start_marker)\n",
    "        if start_idx != -1:\n",
    "            start_idx = text_data.find(\"\\n\", start_idx) + 1\n",
    "            text_data = text_data[start_idx:]\n",
    "        \n",
    "        end_idx = text_data.find(end_marker)\n",
    "        if end_idx != -1:\n",
    "            text_data = text_data[:end_idx]\n",
    "        \n",
    "        combined_text += text_data + \"\\n\\n\"\n",
    "    \n",
    "    return combined_text\n",
    "\n",
    "# Load the training data\n",
    "print(\"Loading training data...\")\n",
    "text_data = download_gutenberg_texts()\n",
    "\n",
    "print(f\"Total characters loaded: {len(text_data):,}\")\n",
    "print(f\"First 200 characters:\\n{text_data[:200]}\")\n",
    "print(f\"\\nLast 200 characters:\\n{text_data[-200:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "269e7435-1ef4-400a-9828-c1ab38d0131a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Gemma tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22774dd039d142db9eeb278e0d33c509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n",
      "Tokenization completed in 0.05 seconds\n",
      "Total tokens: 38,315\n",
      "Compression ratio: 3.77 characters per token\n",
      "Unique tokens in data: 3,833\n",
      "\n",
      "Sample text: 'The quick brown fox jumps over the lazy dog.'\n",
      "Token count: 11\n",
      "Token IDs: [2, 818, 3823, 8864, 37423, 38167, 1024, 506, 31770, 4799]...\n",
      "Decoded back: '<bos>The quick brown fox jumps over the lazy dog.'\n"
     ]
    }
   ],
   "source": [
    "### Tokenizer Setup and Data Analysis\n",
    "# \n",
    "# Gemma uses a much larger vocabulary (262k tokens) compared to GPT-2 (50k tokens).\n",
    "# Let's set up the tokenizer and analyze our data.\n",
    "\n",
    "# Download and setup Gemma tokenizer\n",
    "USE_INSTRUCT_MODEL = False  # Set to True if you want to use the instruct variant\n",
    "\n",
    "repo_id = \"google/gemma-3-270m-it\" if USE_INSTRUCT_MODEL else \"google/gemma-3-270m\"\n",
    "local_dir = Path(repo_id).parts[-1]\n",
    "\n",
    "# Download tokenizer\n",
    "tokenizer_file_path = os.path.join(local_dir, \"tokenizer.json\")\n",
    "if not os.path.exists(tokenizer_file_path):\n",
    "    print(\"Downloading Gemma tokenizer...\")\n",
    "    # Note: You may need to authenticate with Hugging Face here\n",
    "    # from huggingface_hub import login\n",
    "    # login()\n",
    "    tokenizer_file_path = hf_hub_download(\n",
    "        repo_id=repo_id, \n",
    "        filename=\"tokenizer.json\", \n",
    "        local_dir=local_dir\n",
    "    )\n",
    "\n",
    "# Initialize tokenizer\n",
    "class GemmaTokenizer:\n",
    "    def __init__(self, tokenizer_file_path: str):\n",
    "        self._tok = Tokenizer.from_file(str(tokenizer_file_path))\n",
    "        self.eos_token = \"<end_of_turn>\"\n",
    "        self.pad_token = \"<end_of_turn>\"\n",
    "        \n",
    "    def encode(self, text: str) -> list[int]:\n",
    "        return self._tok.encode(text).ids\n",
    "    \n",
    "    def decode(self, ids: list[int]) -> str:\n",
    "        return self._tok.decode(ids, skip_special_tokens=False)\n",
    "\n",
    "tokenizer = GemmaTokenizer(tokenizer_file_path=tokenizer_file_path)\n",
    "\n",
    "# Analyze tokenization\n",
    "print(\"Tokenizing data...\")\n",
    "start_time = time.time()\n",
    "all_tokens = tokenizer.encode(text_data)\n",
    "tokenization_time = time.time() - start_time\n",
    "\n",
    "print(f\"Tokenization completed in {tokenization_time:.2f} seconds\")\n",
    "print(f\"Total tokens: {len(all_tokens):,}\")\n",
    "print(f\"Compression ratio: {len(text_data) / len(all_tokens):.2f} characters per token\")\n",
    "print(f\"Unique tokens in data: {len(set(all_tokens)):,}\")\n",
    "\n",
    "# Sample tokenization\n",
    "sample_text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sample_tokens = tokenizer.encode(sample_text)\n",
    "print(f\"\\nSample text: '{sample_text}'\")\n",
    "print(f\"Token count: {len(sample_tokens)}\")\n",
    "print(f\"Token IDs: {sample_tokens[:10]}...\")  # Show first 10\n",
    "print(f\"Decoded back: '{tokenizer.decode(sample_tokens)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6385a29-634f-4f9c-ae1c-3581472c561e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Estimation:\n",
      "  Model weights: 0.81 GB\n",
      "  Optimizer states: 1.62 GB\n",
      "  Activations (approx): 0.02 GB\n",
      "  Total estimated: 2.46 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Model Configuration and Memory Planning\n",
    "# \n",
    "# Let's configure the model for our available GPU memory (12-13GB target)\n",
    "\n",
    "# Gemma 3 270M configuration\n",
    "GEMMA3_CONFIG_270M = {\n",
    "    \"vocab_size\": 262_144,\n",
    "    \"context_length\": 512,  # Reduced for memory constraints (original: 32,768)\n",
    "    \"emb_dim\": 640,\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 18,\n",
    "    \"hidden_dim\": 2048,\n",
    "    \"head_dim\": 256,\n",
    "    \"qk_norm\": True,\n",
    "    \"n_kv_groups\": 1,\n",
    "    \"rope_local_base\": 10_000.0,\n",
    "    \"rope_base\": 1_000_000.0,\n",
    "    \"sliding_window\": 512,\n",
    "    \"layer_types\": [\n",
    "        \"sliding_attention\", \"sliding_attention\", \"sliding_attention\",\n",
    "        \"sliding_attention\", \"sliding_attention\", \"full_attention\",\n",
    "        \"sliding_attention\", \"sliding_attention\", \"sliding_attention\",\n",
    "        \"sliding_attention\", \"sliding_attention\", \"full_attention\",\n",
    "        \"sliding_attention\", \"sliding_attention\", \"sliding_attention\",\n",
    "        \"sliding_attention\", \"sliding_attention\", \"full_attention\"\n",
    "    ],\n",
    "    \"dtype\": torch.bfloat16,\n",
    "    \"query_pre_attn_scalar\": 256,\n",
    "}\n",
    "\n",
    "# Training settings optimized for memory constraints\n",
    "TRAINING_SETTINGS = {\n",
    "    \"use_pretrained\": True,  # Start from pretrained weights\n",
    "    \"use_instruct\": USE_INSTRUCT_MODEL,\n",
    "    \"context_length\": 512,  # Adjust based on your GPU memory\n",
    "    \"batch_size\": 1,\n",
    "    \"gradient_accumulation_steps\": 4,  # Simulate batch_size=4\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"num_epochs\": 3,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_steps\": 100,\n",
    "}\n",
    "\n",
    "# Memory estimation\n",
    "def estimate_memory_usage(config, settings):\n",
    "    \"\"\"Estimate GPU memory requirements\"\"\"\n",
    "    # Model parameters\n",
    "    total_params = (\n",
    "        config[\"vocab_size\"] * config[\"emb_dim\"] +  # Token embeddings\n",
    "        config[\"n_layers\"] * (\n",
    "            4 * config[\"emb_dim\"]**2 +  # Attention weights (Q,K,V,O)\n",
    "            3 * config[\"emb_dim\"] * config[\"hidden_dim\"]  # FFN weights\n",
    "        ) +\n",
    "        config[\"emb_dim\"] * config[\"vocab_size\"]  # Output layer\n",
    "    )\n",
    "    \n",
    "    model_memory_gb = (total_params * 2) / (1024**3)  # 2 bytes for bfloat16\n",
    "    \n",
    "    # Optimizer states (Adam uses 2x model memory for momentum and variance)\n",
    "    optimizer_memory_gb = model_memory_gb * 2\n",
    "    \n",
    "    # Activation memory (rough estimate)\n",
    "    seq_len = settings[\"context_length\"]\n",
    "    batch_size = settings[\"batch_size\"]\n",
    "    activation_memory_gb = (\n",
    "        batch_size * seq_len * config[\"emb_dim\"] * config[\"n_layers\"] * 4\n",
    "    ) / (1024**3)\n",
    "    \n",
    "    total_memory_gb = model_memory_gb + optimizer_memory_gb + activation_memory_gb\n",
    "    \n",
    "    print(f\"Memory Estimation:\")\n",
    "    print(f\"  Model weights: {model_memory_gb:.2f} GB\")\n",
    "    print(f\"  Optimizer states: {optimizer_memory_gb:.2f} GB\")\n",
    "    print(f\"  Activations (approx): {activation_memory_gb:.2f} GB\")\n",
    "    print(f\"  Total estimated: {total_memory_gb:.2f} GB\")\n",
    "    \n",
    "    return total_memory_gb\n",
    "\n",
    "estimated_memory = estimate_memory_usage(GEMMA3_CONFIG_270M, TRAINING_SETTINGS)\n",
    "\n",
    "if estimated_memory > 12:\n",
    "    print(f\"\\n⚠️ Warning: Estimated memory usage ({estimated_memory:.1f} GB) exceeds target (12 GB)\")\n",
    "    print(\"Consider reducing context_length or using gradient checkpointing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35861b72-9b66-430b-8d95-8182d3e55a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Sufficient tokens for training: 38,315\n",
      "\n",
      "Data split:\n",
      "  Training: 34,493 tokens (90%)\n",
      "  Validation: 3,824 tokens (10%)\n",
      "\n",
      "Possible training sequences: 67\n",
      "Possible validation sequences: 7\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Data Validation for Training\n",
    "# \n",
    "# Ensure we have enough data for our context windows\n",
    "\n",
    "min_tokens_needed = TRAINING_SETTINGS[\"context_length\"] * 10  # At least 10 sequences\n",
    "\n",
    "if len(all_tokens) < min_tokens_needed:\n",
    "    print(f\"⚠️ Warning: You have {len(all_tokens):,} tokens, but {min_tokens_needed:,} is recommended\")\n",
    "    print(f\"Consider adding more text data or reducing context_length\")\n",
    "else:\n",
    "    print(f\"✓ Sufficient tokens for training: {len(all_tokens):,}\")\n",
    "    \n",
    "# Calculate train/val split\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_text = text_data[:split_idx]\n",
    "val_text = text_data[split_idx:]\n",
    "\n",
    "train_tokens = len(tokenizer.encode(train_text))\n",
    "val_tokens = len(tokenizer.encode(val_text))\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Training: {train_tokens:,} tokens ({train_ratio*100:.0f}%)\")\n",
    "print(f\"  Validation: {val_tokens:,} tokens ({(1-train_ratio)*100:.0f}%)\")\n",
    "\n",
    "# Check if we have enough tokens for even one batch\n",
    "contexts_in_train = train_tokens // TRAINING_SETTINGS[\"context_length\"]\n",
    "contexts_in_val = val_tokens // TRAINING_SETTINGS[\"context_length\"]\n",
    "\n",
    "print(f\"\\nPossible training sequences: {contexts_in_train:,}\")\n",
    "print(f\"Possible validation sequences: {contexts_in_val:,}\")\n",
    "\n",
    "if contexts_in_train < 1 or contexts_in_val < 1:\n",
    "    print(\"❌ Error: Not enough data for the specified context length!\")\n",
    "    print(\"Please reduce context_length or add more training data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79f922bb-91c0-4d91-90d4-e170f7c076d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Gemma 3 270M model...\n",
      "Loading pretrained weights from Hugging Face...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e89c03ca09a4861a5e37f03436560e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/536M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pretrained weights loaded successfully\n",
      "\n",
      "Model Statistics:\n",
      "  Total parameters: 435,870,336\n",
      "  Trainable parameters: 435,870,336\n",
      "  Model size (bfloat16): 0.87 GB\n",
      "  GPU memory allocated: 1.87 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Initialize Model\n",
    "# \n",
    "# Now let's initialize the Gemma model and optionally load pretrained weights\n",
    "\n",
    "print(\"Initializing Gemma 3 270M model...\")\n",
    "\n",
    "# Initialize model\n",
    "model = Gemma3Model(GEMMA3_CONFIG_270M)\n",
    "\n",
    "# Load pretrained weights if specified\n",
    "if TRAINING_SETTINGS[\"use_pretrained\"]:\n",
    "    print(\"Loading pretrained weights from Hugging Face...\")\n",
    "    \n",
    "    weights_file = hf_hub_download(\n",
    "        repo_id=repo_id,\n",
    "        filename=\"model.safetensors\",\n",
    "        local_dir=local_dir,\n",
    "    )\n",
    "    \n",
    "    weights_dict = load_file(weights_file)\n",
    "    load_weights_into_gemma(model, GEMMA3_CONFIG_270M, weights_dict)\n",
    "    del weights_dict  # Free memory immediately\n",
    "    \n",
    "    print(\"✓ Pretrained weights loaded successfully\")\n",
    "else:\n",
    "    print(\"Initializing with random weights (training from scratch)\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Model statistics\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Model size (bfloat16): {total_params * 2 / 1e9:.2f} GB\")\n",
    "\n",
    "# Check GPU memory after model loading\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.synchronize()\n",
    "    allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "    print(f\"  GPU memory allocated: {allocated:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5db3a51-aea0-4b7f-817c-089a69fb12bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation before training:\n",
      "\n",
      "Prompt: 'The meaning of life is'\n",
      "Output: <bos>The meaning of life is not defined by the number of years you live, but by the quality of your life.\n",
      "\n",
      "The quality of your life is the quality of your life\n",
      "\n",
      "Prompt: 'Once upon a time'\n",
      "Output: <bos>Once upon a time, there was a man named John. He was a man of many talents. He was a carpenter, a farmer, a farmer’s son,\n",
      "\n",
      "Prompt: 'In the beginning'\n",
      "Output: <bos>In the beginning of the 20th century, the United States was a country of immigrants. The first immigrants to come to the United States were from Europe.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Pre-training Evaluation\n",
    "# ### Pre-training Evaluation\n",
    "# \n",
    "# Let's see how the model performs before training\n",
    "\n",
    "def generate_text_simple(model, tokenizer, prompt, max_new_tokens=50):\n",
    "    \"\"\"Simple generation for evaluation using the working Gemma generation code\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prompt\n",
    "    token_ids = tokenizer.encode(prompt)\n",
    "    input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get EOS token ID if it exists\n",
    "    try:\n",
    "        eos_token_id = tokenizer.encode(\"<end_of_turn>\")[-1]\n",
    "    except:\n",
    "        eos_token_id = None\n",
    "    \n",
    "    generated_tokens = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get logits for last token\n",
    "            logits = model(input_ids)[:, -1, :]\n",
    "            \n",
    "            # Get next token (greedy)\n",
    "            next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            \n",
    "            # Check for EOS\n",
    "            if eos_token_id is not None and torch.all(next_token == eos_token_id):\n",
    "                break\n",
    "            \n",
    "            generated_tokens.append(next_token.item())\n",
    "            \n",
    "            # Append\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "            \n",
    "            # Truncate if too long\n",
    "            if input_ids.shape[1] > model.cfg[\"context_length\"]:\n",
    "                input_ids = input_ids[:, -model.cfg[\"context_length\"]:]\n",
    "    \n",
    "    # Decode the full sequence\n",
    "    full_sequence = token_ids + generated_tokens\n",
    "    return tokenizer.decode(full_sequence)\n",
    "\n",
    "# Alternative: Use the streaming version from the original notebook\n",
    "def generate_text_stream(model, tokenizer, prompt, max_new_tokens=50):\n",
    "    \"\"\"Using the exact generation code from the working Gemma notebook\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prompt\n",
    "    token_ids = tokenizer.encode(prompt)\n",
    "    input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get EOS token ID\n",
    "    try:\n",
    "        eos_token_id = tokenizer.encode(\"<end_of_turn>\")[-1]\n",
    "    except:\n",
    "        eos_token_id = None\n",
    "    \n",
    "    generated = token_ids.copy()  # Start with the prompt\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            out = model(input_ids)[:, -1]\n",
    "            next_token = torch.argmax(out, dim=-1, keepdim=True)\n",
    "            \n",
    "            if eos_token_id is not None and torch.all(next_token == eos_token_id):\n",
    "                break\n",
    "            \n",
    "            generated.append(next_token.item())\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "            \n",
    "            # Handle context overflow\n",
    "            if input_ids.shape[1] > model.cfg[\"context_length\"]:\n",
    "                input_ids = input_ids[:, -model.cfg[\"context_length\"]:]\n",
    "    \n",
    "    return tokenizer.decode(generated)\n",
    "\n",
    "# Test generation before training\n",
    "test_prompts = [\n",
    "    \"The meaning of life is\",\n",
    "    \"Once upon a time\",\n",
    "    \"In the beginning\",\n",
    "]\n",
    "\n",
    "\n",
    "print(\"Model generation before training:\\n\")\n",
    "for prompt in test_prompts:\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    output = generate_text_simple(model, tokenizer, prompt, max_new_tokens=30)\n",
    "    print(f\"Output: {output}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dc718c32-1934-444e-8f47-3c990dd0c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data loaders...\n",
      "Training batches: 67\n",
      "Validation batches: 7\n",
      "\n",
      "First batch shape - Inputs: torch.Size([1, 512]), Targets: torch.Size([1, 512])\n",
      "First few tokens: [3324, 1116, 3774, 236764, 532, 116644, 586, 1176, 999, 24501]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Create Data Loaders\n",
    "# \n",
    "# Create PyTorch data loaders for training\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GemmaDataset(Dataset):\n",
    "    \"\"\"Dataset for Gemma training\"\"\"\n",
    "    def __init__(self, text, tokenizer, max_length, stride):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.stride = stride\n",
    "        \n",
    "        # Tokenize all text\n",
    "        self.tokens = tokenizer.encode(text)\n",
    "        \n",
    "        # Create sliding windows\n",
    "        self.windows = []\n",
    "        for i in range(0, len(self.tokens) - max_length, stride):\n",
    "            self.windows.append(self.tokens[i:i + max_length + 1])  # +1 for target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.windows)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        window = self.windows[idx]\n",
    "        input_ids = torch.tensor(window[:-1], dtype=torch.long)  # All but last\n",
    "        target_ids = torch.tensor(window[1:], dtype=torch.long)   # All but first\n",
    "        return input_ids, target_ids\n",
    "\n",
    "# Create datasets\n",
    "print(\"Creating data loaders...\")\n",
    "\n",
    "train_dataset = GemmaDataset(\n",
    "    train_text, \n",
    "    tokenizer, \n",
    "    TRAINING_SETTINGS[\"context_length\"],\n",
    "    TRAINING_SETTINGS[\"context_length\"]  # Non-overlapping windows\n",
    ")\n",
    "\n",
    "val_dataset = GemmaDataset(\n",
    "    val_text,\n",
    "    tokenizer,\n",
    "    TRAINING_SETTINGS[\"context_length\"],\n",
    "    TRAINING_SETTINGS[\"context_length\"]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=TRAINING_SETTINGS[\"batch_size\"],\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=TRAINING_SETTINGS[\"batch_size\"],\n",
    "    shuffle=False,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "\n",
    "# Verify data loader\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    print(f\"\\nFirst batch shape - Inputs: {inputs.shape}, Targets: {targets.shape}\")\n",
    "    print(f\"First few tokens: {inputs[0, :10].tolist()}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b018243a-ef6e-442a-a8f0-794d3e7506fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating initial losses...\n",
      "Initial training loss: 3.8344\n",
      "Initial validation loss: 3.6853\n",
      "Initial perplexity: 39.86\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Calculate Initial Loss\n",
    "# \n",
    "# Establish baseline performance metrics\n",
    "\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    \"\"\"Calculate loss for a single batch\"\"\"\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    \n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), \n",
    "        target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    \"\"\"Calculate average loss over data loader\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.\n",
    "    \n",
    "    if num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / num_batches if num_batches > 0 else float(\"nan\")\n",
    "\n",
    "# Calculate initial losses\n",
    "print(\"Calculating initial losses...\")\n",
    "train_loss_initial = calc_loss_loader(train_loader, model, device, num_batches=10)\n",
    "val_loss_initial = calc_loss_loader(val_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Initial training loss: {train_loss_initial:.4f}\")\n",
    "print(f\"Initial validation loss: {val_loss_initial:.4f}\")\n",
    "print(f\"Initial perplexity: {torch.exp(torch.tensor(val_loss_initial)):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3d7fb85-c567-4b36-872a-83d29e5d9c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training for 3 epochs...\n",
      "Total optimization steps: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████| 67/67 [00:03<00:00, 16.79it/s, loss=2.6250, lr=3.84e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Summary:\n",
      "  Avg Train Loss: 2.9142\n",
      "  Val Loss: 2.8326\n",
      "  Val Perplexity: 16.99\n",
      "  ✓ Saved best model\n",
      "\n",
      "  Sample generation:\n",
      "  '<bos>Once upon a time, there was a little girl named Alice, who was a very curious little girl. She was very curious about the world, and she was very curious about the things that were happening in it. She'\n",
      "\n",
      "  GPU memory: 4.34 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████| 67/67 [00:03<00:00, 17.42it/s, loss=2.6562, lr=1.44e-05]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Summary:\n",
      "  Avg Train Loss: 2.3032\n",
      "  Val Loss: 2.8214\n",
      "  Val Perplexity: 16.80\n",
      "  ✓ Saved best model\n",
      "\n",
      "  Sample generation:\n",
      "  '<bos>Once upon a time, there was a little girl named Alice, who was a very curious creature. She was a very clever girl, and she was very fond of playing with the little mouse, the little rabbit, and'\n",
      "\n",
      "  GPU memory: 4.34 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████| 67/67 [00:03<00:00, 17.37it/s, loss=1.7891, lr=1.97e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Summary:\n",
      "  Avg Train Loss: 2.1531\n",
      "  Val Loss: 2.8237\n",
      "  Val Perplexity: 16.84\n",
      "\n",
      "  Sample generation:\n",
      "  '<bos>Once upon a time, there was a little girl named Alice, who was a very curious creature. She was a very clever girl, and she was very fond of playing with the little mouse, the little rabbit, and'\n",
      "\n",
      "  GPU memory: 4.34 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Training Loop\n",
    "# \n",
    "# Now we'll train the model with gradient accumulation to work within memory constraints\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train_gemma(model, train_loader, val_loader, settings, device):\n",
    "    \"\"\"Training loop with gradient accumulation\"\"\"\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=settings[\"learning_rate\"],\n",
    "        weight_decay=settings[\"weight_decay\"],\n",
    "        betas=(0.9, 0.95)\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler (optional)\n",
    "    total_steps = len(train_loader) * settings[\"num_epochs\"] // settings[\"gradient_accumulation_steps\"]\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, \n",
    "        T_max=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"learning_rates\": []\n",
    "    }\n",
    "    \n",
    "    # Training loop\n",
    "    print(f\"\\nStarting training for {settings['num_epochs']} epochs...\")\n",
    "    print(f\"Total optimization steps: {total_steps}\")\n",
    "    \n",
    "    global_step = 0\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(settings[\"num_epochs\"]):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{settings['num_epochs']}\")\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, (input_batch, target_batch) in enumerate(progress_bar):\n",
    "            # Forward pass\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss = loss / settings[\"gradient_accumulation_steps\"]\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            epoch_loss += loss.item() * settings[\"gradient_accumulation_steps\"]\n",
    "            \n",
    "            # Update weights after accumulation\n",
    "            if (batch_idx + 1) % settings[\"gradient_accumulation_steps\"] == 0:\n",
    "                # Gradient clipping\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                global_step += 1\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{loss.item() * settings[\"gradient_accumulation_steps\"]:.4f}',\n",
    "                    'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "                })\n",
    "        \n",
    "        # Calculate epoch metrics\n",
    "        avg_train_loss = epoch_loss / len(train_loader)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=20)\n",
    "        \n",
    "        history[\"train_loss\"].append(avg_train_loss)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"learning_rates\"].append(scheduler.get_last_lr()[0])\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Avg Train Loss: {avg_train_loss:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"  Val Perplexity: {torch.exp(torch.tensor(val_loss)):.2f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), \"gemma3_best.pth\")\n",
    "            print(\"  ✓ Saved best model\")\n",
    "        \n",
    "        # Generate sample\n",
    "        print(f\"\\n  Sample generation:\")\n",
    "        prompt = \"Once upon a time\"\n",
    "        output = generate_text_simple(model, tokenizer, prompt, max_new_tokens=40)\n",
    "        print(f\"  '{output}'\")\n",
    "        \n",
    "        # Check GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "            print(f\"\\n  GPU memory: {allocated:.2f} GB\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Run training\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "history = train_gemma(model, train_loader, val_loader, TRAINING_SETTINGS, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22ffb206-22e1-459e-9366-a85d92f5733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Complete!\n",
      "Initial val loss: 3.6853 → Final val loss: 2.8237\n",
      "Improvement: 23.4%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Training Results Visualization\n",
    "# \n",
    "# Plot the training curves to analyze performance\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history[\"train_loss\"], label=\"Train Loss\", marker='o')\n",
    "axes[0].plot(history[\"val_loss\"], label=\"Val Loss\", marker='s')\n",
    "axes[0].set_xlabel(\"Epoch\")\n",
    "axes[0].set_ylabel(\"Loss\")\n",
    "axes[0].set_title(\"Training and Validation Loss\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Perplexity\n",
    "train_perplexity = [torch.exp(torch.tensor(loss)).item() for loss in history[\"train_loss\"]]\n",
    "val_perplexity = [torch.exp(torch.tensor(loss)).item() for loss in history[\"val_loss\"]]\n",
    "\n",
    "axes[1].plot(train_perplexity, label=\"Train Perplexity\", marker='o')\n",
    "axes[1].plot(val_perplexity, label=\"Val Perplexity\", marker='s')\n",
    "axes[1].set_xlabel(\"Epoch\")\n",
    "axes[1].set_ylabel(\"Perplexity\")\n",
    "axes[1].set_title(\"Perplexity Over Time\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[2].plot(history[\"learning_rates\"], marker='o', color='green')\n",
    "axes[2].set_xlabel(\"Epoch\")\n",
    "axes[2].set_ylabel(\"Learning Rate\")\n",
    "axes[2].set_title(\"Learning Rate Schedule\")\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"gemma_training_results.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nTraining Complete!\")\n",
    "print(f\"Initial val loss: {val_loss_initial:.4f} → Final val loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"Improvement: {(val_loss_initial - history['val_loss'][-1]) / val_loss_initial * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bda63040-9c75-4f1d-9454-25a5078cab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generation after training:\n",
      "\n",
      "Prompt: 'The meaning of life is'\n",
      "Output: <bos>The meaning of life is to live a life of love, and to love your enemies.\n",
      "\n",
      "“Love your enemies, and you will win,” said the Lord.\n",
      "\n",
      "“I’m not talking about the enemies,” said the King. “I’m talking about the\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: 'Once upon a time'\n",
      "Output: <bos>Once upon a time, there was a little girl named Alice, who was a very curious creature. She was a very clever girl, and she was very fond of playing with the little mouse, the little rabbit, and the little frog.\n",
      "\n",
      "One day, Alice was\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: 'In the beginning'\n",
      "Output: <bos>In the beginning, I was a little nervous about the whole thing. I was a little nervous about the fact that I was going to be the first person to walk the length of the Earth, and I was afraid that I might get lost. I was afraid that\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Prompt: 'To be or not to be'\n",
      "Output: <bos>To be or not to be?\n",
      "\n",
      "That’s the question that has been swirling around the minds of many a young person in the last few weeks.\n",
      "\n",
      "The question is, “Is it right?”\n",
      "\n",
      "“Yes,” said one of the students, “it is.”\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Post-Training Evaluation\n",
    "# \n",
    "# Compare model performance before and after training\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load(\"gemma3_best.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(\"Model generation after training:\\n\")\n",
    "\n",
    "# Test with same prompts as before\n",
    "test_prompts = [\n",
    "    \"The meaning of life is\",\n",
    "    \"Once upon a time\",\n",
    "    \"In the beginning\",\n",
    "    \"To be or not to be\",\n",
    "]\n",
    "\n",
    "for prompt in test_prompts:\n",
    "    print(f\"Prompt: '{prompt}'\")\n",
    "    output = generate_text_simple(model, tokenizer, prompt, max_new_tokens=50)\n",
    "    print(f\"Output: {output}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a800a07-f69a-423a-ab8e-70133dc164b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different generation strategies:\n",
      "\n",
      "Conservative (temp=0.5, top_k=10):\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m config \u001b[38;5;129;01min\u001b[39;00m generation_configs:\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (temp=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, top_k=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[33m'\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m):\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     68\u001b[39m     output = generate_advanced(\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m         model, \u001b[43mtokenizer\u001b[49m, prompt, \n\u001b[32m     70\u001b[39m         temperature=config[\u001b[33m'\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m'\u001b[39m], \n\u001b[32m     71\u001b[39m         top_k=config[\u001b[33m'\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     72\u001b[39m         max_new_tokens=\u001b[32m50\u001b[39m\n\u001b[32m     73\u001b[39m     )\n\u001b[32m     74\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m80\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# ### Advanced Generation with Temperature and Top-k\n",
    "# \n",
    "# Test more sophisticated generation strategies\n",
    "\n",
    "def generate_advanced(model, tokenizer, prompt, max_new_tokens=50, temperature=0.8, top_k=50):\n",
    "    \"\"\"Advanced generation with temperature and top-k sampling\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prompt\n",
    "    token_ids = tokenizer.encode(prompt)\n",
    "    input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get EOS token ID\n",
    "    try:\n",
    "        eos_token_id = tokenizer.encode(\"<end_of_turn>\")[-1]\n",
    "    except:\n",
    "        eos_token_id = None\n",
    "    \n",
    "    generated = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            # Get logits\n",
    "            logits = model(input_ids)[:, -1, :]\n",
    "            \n",
    "            # Apply temperature\n",
    "            if temperature > 0:\n",
    "                logits = logits / temperature\n",
    "            \n",
    "            # Top-k filtering\n",
    "            if top_k > 0:\n",
    "                indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
    "                logits[indices_to_remove] = float('-inf')\n",
    "            \n",
    "            # Sample\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            next_token = torch.multinomial(probs, num_samples=1)\n",
    "            \n",
    "            # Check for EOS\n",
    "            if eos_token_id is not None and torch.all(next_token == eos_token_id):\n",
    "                break\n",
    "            \n",
    "            generated.append(next_token.item())\n",
    "            \n",
    "            # Append\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "            \n",
    "            # Truncate if needed\n",
    "            if input_ids.shape[1] > model.cfg[\"context_length\"]:\n",
    "                input_ids = input_ids[:, -model.cfg[\"context_length\"]:]\n",
    "    \n",
    "    # Decode full sequence\n",
    "    full_sequence = token_ids + generated\n",
    "    return tokenizer.decode(full_sequence)\n",
    "\n",
    "# Test different generation settings\n",
    "generation_configs = [\n",
    "    {\"temperature\": 0.5, \"top_k\": 10, \"name\": \"Conservative\"},\n",
    "    {\"temperature\": 0.8, \"top_k\": 50, \"name\": \"Balanced\"},\n",
    "    {\"temperature\": 1.2, \"top_k\": 100, \"name\": \"Creative\"},\n",
    "]\n",
    "\n",
    "prompt = \"The future of artificial intelligence\"\n",
    "\n",
    "print(\"Testing different generation strategies:\\n\")\n",
    "for config in generation_configs:\n",
    "    print(f\"{config['name']} (temp={config['temperature']}, top_k={config['top_k']}):\")\n",
    "    output = generate_advanced(\n",
    "        model, tokenizer, prompt, \n",
    "        temperature=config['temperature'], \n",
    "        top_k=config['top_k'],\n",
    "        max_new_tokens=50\n",
    "    )\n",
    "    print(f\"{output}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5fe2dfb7-699b-443f-b499-2b409f75ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for what?\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    \"\"\"Generate and print a sample during training\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Encode prompt\n",
    "    token_ids = tokenizer.encode(start_context)\n",
    "    input_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get EOS token ID\n",
    "    try:\n",
    "        eos_token_id = tokenizer.encode(\"<end_of_turn>\")[-1]\n",
    "    except:\n",
    "        eos_token_id = None\n",
    "    \n",
    "    generated = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(50):  # max_new_tokens\n",
    "            logits = model(input_ids)[:, -1, :]\n",
    "            next_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "            \n",
    "            if eos_token_id is not None and torch.all(next_token == eos_token_id):\n",
    "                break\n",
    "            \n",
    "            generated.append(next_token.item())\n",
    "            input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "            \n",
    "            # Handle context overflow\n",
    "            if input_ids.shape[1] > model.cfg[\"context_length\"]:\n",
    "                input_ids = input_ids[:, -model.cfg[\"context_length\"]:]\n",
    "    \n",
    "    # Decode and print\n",
    "    full_sequence = token_ids + generated\n",
    "    decoded_text = tokenizer.decode(full_sequence)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "89896728-b585-4ea9-8b9b-1ebc5a747381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Summary\n",
      "==================================================\n",
      "Model: Gemma 3 270M\n",
      "Training data size: 38,315 tokens\n",
      "Context length: 512\n",
      "Batch size: 1 (effective: 4)\n",
      "Learning rate: 5e-05\n",
      "Epochs: 3\n",
      "\n",
      "Results:\n",
      "  Initial loss: 3.6853\n",
      "  Final loss: 2.8237\n",
      "  Best loss: 2.8214\n",
      "  Improvement: 23.4%\n",
      "\n",
      "Peak GPU memory usage: 5.64 GB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Save Final Model and Training Summary\n",
    "# \n",
    "# Save the trained model and create a summary report\n",
    "\n",
    "# Save final model with metadata\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'config': GEMMA3_CONFIG_270M,\n",
    "    'training_settings': TRAINING_SETTINGS,\n",
    "    'training_history': history,\n",
    "    'final_metrics': {\n",
    "        'final_train_loss': history['train_loss'][-1],\n",
    "        'final_val_loss': history['val_loss'][-1],\n",
    "        'best_val_loss': min(history['val_loss']),\n",
    "        'total_epochs': TRAINING_SETTINGS['num_epochs']\n",
    "    }\n",
    "}, 'gemma3_trained_complete.pth')\n",
    "\n",
    "print(\"Training Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model: Gemma 3 270M\")\n",
    "print(f\"Training data size: {len(all_tokens):,} tokens\")\n",
    "print(f\"Context length: {TRAINING_SETTINGS['context_length']}\")\n",
    "print(f\"Batch size: {TRAINING_SETTINGS['batch_size']} (effective: {TRAINING_SETTINGS['batch_size'] * TRAINING_SETTINGS['gradient_accumulation_steps']})\")\n",
    "print(f\"Learning rate: {TRAINING_SETTINGS['learning_rate']}\")\n",
    "print(f\"Epochs: {TRAINING_SETTINGS['num_epochs']}\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Initial loss: {val_loss_initial:.4f}\")\n",
    "print(f\"  Final loss: {history['val_loss'][-1]:.4f}\")\n",
    "print(f\"  Best loss: {min(history['val_loss']):.4f}\")\n",
    "print(f\"  Improvement: {(1 - min(history['val_loss'])/val_loss_initial) * 100:.1f}%\")\n",
    "\n",
    "# Memory usage summary\n",
    "if torch.cuda.is_available():\n",
    "    max_allocated = torch.cuda.max_memory_allocated() / 1024**3\n",
    "    print(f\"\\nPeak GPU memory usage: {max_allocated:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72c10f1-ec8b-41d5-abc2-bb86ba983fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1158b-abc7-46ab-b390-1cc5c2659185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "33b647dc-f6ed-45b3-8ede-58a5c423bb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for Further Training:\n",
      "\n",
      "⚠️ Validation loss increased in last epoch - possible overfitting\n",
      "   Consider: reducing learning rate, adding dropout, or early stopping\n",
      "\n",
      "Potential improvements:\n",
      "1. Data: Add more diverse texts from Project Gutenberg\n",
      "2. Context: Try longer sequences if memory allows (current: 512)\n",
      "3. Batch size: Use gradient accumulation to simulate larger batches\n",
      "4. Learning rate: Experiment with warmup and different schedules\n",
      "5. Fine-tuning: Try task-specific datasets for better performance\n",
      "\n",
      "==================================================\n",
      "To load this model later, use:\n",
      "\n",
      "\n",
      "# Load the trained model\n",
      "checkpoint = torch.load('gemma3_trained_complete.pth', map_location=device)\n",
      "model = Gemma3Model(checkpoint['config'])\n",
      "model.load_state_dict(checkpoint['model_state_dict'])\n",
      "model.to(device)\n",
      "model.eval()\n",
      "\n",
      "# View training history\n",
      "history = checkpoint['training_history']\n",
      "print(f\"Best validation loss: {checkpoint['final_metrics']['best_val_loss']:.4f}\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ### Next Steps and Recommendations\n",
    "# \n",
    "# Based on the training results, here are some suggestions for further improvement:\n",
    "\n",
    "print(\"Recommendations for Further Training:\\n\")\n",
    "\n",
    "# Analyze if model is overfitting or underfitting\n",
    "if len(history['val_loss']) > 1:\n",
    "    if history['val_loss'][-1] > history['val_loss'][-2]:\n",
    "        print(\"⚠️ Validation loss increased in last epoch - possible overfitting\")\n",
    "        print(\"   Consider: reducing learning rate, adding dropout, or early stopping\")\n",
    "    elif abs(history['train_loss'][-1] - history['val_loss'][-1]) > 0.5:\n",
    "        print(\"⚠️ Large gap between train and val loss - likely overfitting\")\n",
    "        print(\"   Consider: more regularization, data augmentation, or smaller model\")\n",
    "    elif history['train_loss'][-1] > 3.0:\n",
    "        print(\"⚠️ Training loss still high - possible underfitting\")\n",
    "        print(\"   Consider: longer training, higher learning rate, or more complex model\")\n",
    "    else:\n",
    "        print(\"✓ Training appears stable and converged well\")\n",
    "\n",
    "print(\"\\nPotential improvements:\")\n",
    "print(\"1. Data: Add more diverse texts from Project Gutenberg\")\n",
    "print(\"2. Context: Try longer sequences if memory allows (current: 512)\")\n",
    "print(\"3. Batch size: Use gradient accumulation to simulate larger batches\")\n",
    "print(\"4. Learning rate: Experiment with warmup and different schedules\")\n",
    "print(\"5. Fine-tuning: Try task-specific datasets for better performance\")\n",
    "\n",
    "# Provide code snippet for loading the model later\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"To load this model later, use:\\n\")\n",
    "print(\"\"\"\n",
    "# Load the trained model\n",
    "checkpoint = torch.load('gemma3_trained_complete.pth', map_location=device)\n",
    "model = Gemma3Model(checkpoint['config'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# View training history\n",
    "history = checkpoint['training_history']\n",
    "print(f\"Best validation loss: {checkpoint['final_metrics']['best_val_loss']:.4f}\")\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63fb5c8a-562f-49d7-8e57-c7f0d33537f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the complete model for continued training or inference\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "811d7785-587d-4914-a1b7-dc783044cc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Training epochs completed: 3\n",
      "Best validation loss: 2.8214\n"
     ]
    }
   ],
   "source": [
    "# Reload the complete model for continued training or inference\n",
    "import torch\n",
    "\n",
    "# Load the checkpoint\n",
    "checkpoint = torch.load('gemma3_trained_complete.pth', map_location=device)\n",
    "\n",
    "# Recreate the model with the same configuration\n",
    "model = Gemma3Model(checkpoint['config'])\n",
    "\n",
    "# Load the state dictionary\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033926fd-a4b2-4018-bc81-2a66d8bf3d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to continue training, set to train mode\n",
    "# model.train()\n",
    "\n",
    "# # Access training history if needed\n",
    "# training_history = checkpoint['training_history']\n",
    "# final_metrics = checkpoint['final_metrics']\n",
    "\n",
    "# # Print out some information\n",
    "# print(\"Model loaded successfully\")\n",
    "# print(f\"Training epochs completed: {final_metrics['total_epochs']}\")\n",
    "# print(f\"Best validation loss: {final_metrics['best_val_loss']:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174b24fa-765c-4387-9580-eed21382fa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66d1bc9f-9f06-4a0a-a657-71b52e1ccc1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing different generation strategies:\n",
      "\n",
      "Conservative (temp=0.5, top_k=10):\n",
      "<bos>The future of artificial intelligence (AI) is poised to revolutionize many aspects of our lives, and it's clear that this technology will have a profound impact on the world.  While the potential benefits are immense, the development and deployment of AI also raise significant ethical and societal\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Balanced (temp=0.8, top_k=50):\n",
      "<bos>The future of artificial intelligence (AI) is poised for profound and transformative changes across various sectors. While the potential benefits are undeniable, the rapid advancement of AI technologies presents significant challenges and ethical considerations that must be carefully addressed. This paper explores the multifaceted challenges and opportunities presented by AI\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Creative (temp=1.2, top_k=100):\n",
      "<bos>The future of artificial intelligence (AI) is rapidly evolving, and its impact on society is profound. With AI-driven innovations, we are striving to develop more autonomous and adaptable systems that can handle complex challenges and contribute to better human lives.\n",
      "\n",
      "AI's capabilities in areas\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test different generation settings\n",
    "generation_configs = [\n",
    "    {\"temperature\": 0.5, \"top_k\": 10, \"name\": \"Conservative\"},\n",
    "    {\"temperature\": 0.8, \"top_k\": 50, \"name\": \"Balanced\"},\n",
    "    {\"temperature\": 1.2, \"top_k\": 100, \"name\": \"Creative\"},\n",
    "]\n",
    "\n",
    "prompt = \"The future of artificial intelligence\"\n",
    "\n",
    "print(\"Testing different generation strategies:\\n\")\n",
    "for config in generation_configs:\n",
    "    print(f\"{config['name']} (temp={config['temperature']}, top_k={config['top_k']}):\")\n",
    "    output = generate_advanced(\n",
    "        model, tokenizer, prompt, \n",
    "        temperature=config['temperature'], \n",
    "        top_k=config['top_k'],\n",
    "        max_new_tokens=50\n",
    "    )\n",
    "    print(f\"{output}\\n\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169cd342-110a-459e-b200-da5a30d83fba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
